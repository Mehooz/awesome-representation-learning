# Reading List for Topics in Representation Learning
By [Minghao Zhang](https://www.minghaozhang.com). Since the author only focuses on specific directions, so it just covers small numbers of deep learning areas. If there is anything wrong and missed, just let me know!


## Table of Contents
* [Research Papers](#research-papers)
  * [Survey Papers](#survey-papers)
* [Core Areas](#core-areas)
  * [Generative Model](#generative-model)
  * [Non-Generative Model](#non-generative-model)
  * [Representation Learning in Reinforcement Learning](#representation-learning-in-reinforcement-learning)
  * [Disentangled Representation](#generative-model)
  * [Object-based Representation](#generative-model)
* [Workshops](#workshops)
* [Courses](#courses)


# Research Papers

## Survey

[Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods](https://arxiv.org/abs/1907.09358), arXiv 2019

[Representation Learning: A Review and New Perspectives](https://arxiv.org/abs/1206.5538), TPAMI 2013

[Self-supervised Learning: Generative or Contrastive](https://arxiv.org/pdf/2006.08218.pdf), arxiv

## Core Areas

### Generative Model

[Made: Masked autoencoder for distribution estimation](https://arxiv.org/pdf/1502.03509.pdf), ICML 2015

[Wavenet: A generative model for raw audio](https://arxiv.org/pdf/1609.03499.pdf), arxiv

[Pixel Recurrent Neural Networks](https://arxiv.org/pdf/1601.06759.pdf), ICML 2016

[Conditional Image Generation withPixelCNN Decoders](https://papers.nips.cc/paper/6527-conditional-image-generation-with-pixelcnn-decoders.pdf), NeurIPS 2016

[Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications](https://arxiv.org/pdf/1701.05517.pdf), arxiv

[Pixelsnail: An improved autoregressive generative model](http://proceedings.mlr.press/v80/chen18h/chen18h.pdf), ICML 2018

[Parallel Multiscale Autoregressive Density Estimation](https://arxiv.org/pdf/1703.03664.pdf), arxiv

[Flow++: Improving Flow-Based Generative Models with VariationalDequantization and Architecture Design](https://arxiv.org/pdf/1902.00275.pdf), ICML 2019

[Improved Variational Inferencewith Inverse Autoregressive Flow](https://arxiv.org/pdf/1606.04934.pdf), NeurIPS 2016

[Glow: Generative Flowwith Invertible 1Ã—1 Convolutions](https://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions.pdf), NeurIPS 2018

[Masked Autoregressive Flow for Density Estimation](https://arxiv.org/pdf/1705.07057.pdf), NeurIPS 2017

[Neural Discrete Representation Learning](https://arxiv.org/pdf/1711.00937.pdf), NeurIPS 2017


### Non-Generative Model

[Unsupervised Visual Representation Learning by Context Prediction](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Doersch_Unsupervised_Visual_Representation_ICCV_2015_paper.pdf), ICCV 2015

[Distributed Representations of Words and Phrasesand their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf), NeurIPS 2013

[Representation Learning withContrastive Predictive Coding](https://arxiv.org/pdf/1807.03748.pdf), arxiv

[Contrastive Multiview Coding](https://openreview.net/pdf?id=BkgStySKPB), ICLR 2020

[Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/pdf/1911.05722.pdf), arxiv

[A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf), arxiv

[Contrastive Representation Distillation](https://arxiv.org/pdf/1910.10699.pdf), ICLR 2020

[Neural Predictive Belief Representations](https://arxiv.org/pdf/1811.06407v2.pdf), arxiv

[World Discovery Models](https://arxiv.org/pdf/1902.07685.pdf), ICML 2019

[Deep Variational Information Bottleneck](https://arxiv.org/pdf/1612.00410.pdf), ICLR 2017

[Learning deep representations by mutual information estimation and maximization](https://arxiv.org/pdf/1808.06670.pdf), ICLR 2019

[Putting An End to End-to-End:Gradient-Isolated Learning of Representations](https://papers.nips.cc/paper/8568-putting-an-end-to-end-to-end-gradient-isolated-learning-of-representations.pdf), NeurIPS 2019

[What Makes for Good Views for Contrastive Learning?](https://arxiv.org/pdf/2005.10243.pdf), arxiv

[Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning](https://arxiv.org/pdf/2006.07733.pdf), arxiv

[Mitigating Embedding and Class Assignment Mismatch in Unsupervised Image Classification](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690749.pdf), ECCV 2020

[Improving Unsupervised Image Clustering With Robust Learning](https://arxiv.org/pdf/2012.11150.pdf), CVPR 2021


### Representation Learning in Reinforcement Learning


[InfoBot: Transfer and Exploration via the Information Bottleneck](https://arxiv.org/pdf/1901.10902.pdf), ICLR 2019

[Reinforcement Learning with Unsupervised Auxiliary Tasks](https://arxiv.org/pdf/1611.05397.pdf), ICLR 2017

[World Models](https://arxiv.org/pdf/1803.10122.pdf), arxiv

[Learning Latent Dynamics for Planning from Pixels](http://proceedings.mlr.press/v97/hafner19a/hafner19a.pdf), ICML 2019

[Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images](https://papers.nips.cc/paper/5964-embed-to-control-a-locally-linear-latent-dynamics-model-for-control-from-raw-images.pdf), NeurIPS 2015

[DARLA: Improving Zero-Shot Transfer in Reinforcement Learning](https://arxiv.org/pdf/1707.08475.pdf), ICML 2017

[Count-Based Exploration with Neural Density Models](https://arxiv.org/pdf/1703.01310.pdf), ICML 2017

[Learning Actionable Representations with Goal-Conditioned Policies](https://arxiv.org/pdf/1811.07819.pdf), ICLR 2019

[Automatic Goal Generation for Reinforcement Learning Agents](https://arxiv.org/pdf/1705.06366.pdf), ICML 2018

[VIME: Variational Information Maximizing Exploration](https://arxiv.org/pdf/1605.09674.pdf), NeurIPS 2017

[Unsupervised State Representation Learning in Atari](http://papers.nips.cc/paper/9081-unsupervised-state-representation-learning-in-atari.pdf), NeurIPS 2019

[Learning Invariant Representations for Reinforcement Learning without Reconstruction](https://arxiv.org/pdf/2006.10742.pdf), arxiv

[CURL: Contrastive Unsupervised Representations for Reinforcement Learning](https://arxiv.org/pdf/2004.04136.pdf), arxiv

[DeepMDP: Learning Continuous Latent Space Models for Representation Learning](http://proceedings.mlr.press/v97/gelada19a/gelada19a.pdf), ICML 2019


### Disentangled Representation 


[beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework](https://openreview.net/pdf?id=Sy2fzU9gl), ICLR 2017

[Isolating Sources of Disentanglement in Variational Autoencoders](https://arxiv.org/pdf/1802.04942.pdf), NeurIPS 2018

[Disentangling by Factorising](https://arxiv.org/pdf/1802.05983.pdf), ICML 2018

[InfoGAN: Interpretable Representation Learning byInformation Maximizing Generative Adversarial Nets](https://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf), NeurIPS 2016

[Spatial Broadcast Decoder: A Simple Architecture forLearning Disentangled Representations in VAEs](https://arxiv.org/pdf/1901.07017.pdf), arxiv

[Challenging Common Assumptions in the Unsupervised Learning ofDisentangled Representations](https://arxiv.org/pdf/1811.12359.pdf), ICML 2019


### Object-based Representation  


[Contrastive Learning of Structured World Models ](https://openreview.net/pdf?id=H1gax6VtDB), ICLR 2020

[Entity Abstraction in Visual Model-Based Reinforcement Learning](https://arxiv.org/pdf/1910.12827.pdf), CoRL 2019

[Reasoning About Physical Interactions with Object-Oriented Prediction and Planning](https://arxiv.org/pdf/1812.10972.pdf), ICLR 2019

[Object-oriented state editing for HRL](https://arxiv.org/pdf/1910.14361.pdf), NeurIPS 2019

[MONet: Unsupervised Scene Decomposition and Representation](https://arxiv.org/abs/1901.11390.pdf), arxiv

[Multi-Object Representation Learning with Iterative Variational Inference](https://arxiv.org/pdf/1903.00450.pdf), ICML 2019

[GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations](https://arxiv.org/pdf/1907.13052.pdf), ICLR 2020

[Generative Modeling of Infinite Occluded Objects for Compositional Scene Representation](http://proceedings.mlr.press/v97/yuan19b/yuan19b.pdf), ICML 2019

[SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition](https://arxiv.org/pdf/2001.02407.pdf), arxiv

[COBRA: Data-Efficient Model-Based RL through Unsupervised Object Discovery and Curiosity-Driven Exploration](https://arxiv.org/pdf/1905.09275v2.pdf), arxiv

[Object-Oriented Dynamics Predictor](https://arxiv.org/pdf/1806.07371.pdf), NeurIPS 2018

[Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions](https://arxiv.org/pdf/1802.10353.pdf), ICLR 2018

[Unsupervised Video Object Segmentation for Deep Reinforcement Learning](https://arxiv.org/pdf/1805.07780.pdf), NeurIPS 2018

[Object-Oriented Dynamics Learning through Multi-Level Abstraction](https://arxiv.org/pdf/1904.07482.pdf), AAAI 2019

[Language as an Abstraction for Hierarchical Deep Reinforcement Learning](https://arxiv.org/pdf/1906.07343.pdf), NeurIPS 2019

[Interaction Networks for Learning about Objects, Relations and Physics](https://arxiv.org/pdf/1612.00222.pdf), NeurIPS 2016

[Learning Compositional Koopman Operators for Model-Based Control](https://arxiv.org/pdf/1910.08264.pdf), ICLR 2020

[Unmasking the Inductive Biases of Unsupervised Object Representations for Video Sequences](https://arxiv.org/pdf/2006.07034.pdf), arxiv


# Workshops


[Graph Representation Learning](https://grlearning.github.io/), NeurIPS 2019

[Workshop on Representation Learning for NLP](https://sites.google.com/view/repl4nlp2020/), ACL 2016-2020


# Courses
[Berkeley CS 294-158, Deep Unsupervised Learning](https://sites.google.com/view/berkeley-cs294-158-sp19/home)



